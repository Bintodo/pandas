{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据规整化：清理、转换、合并、重塑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目录\n",
    "+ 合并数据集\n",
    " + 数据库风格的DataFrame合并  \n",
    "列对列连接，DataFrame索引被丢弃\n",
    "   + 一个键\n",
    "     + 多对一\n",
    "     + 多对多\n",
    "   + 多个键\n",
    "   + 对重复列名的处理\n",
    " + 索引上的合并\n",
    "   + 列对索引\n",
    "     + 层次化索引\n",
    "   + 索引对索引\n",
    "   + join方法\n",
    "     + 一组DataFrame\n",
    " + 轴向连接  \n",
    " concat函数\n",
    "   + NumPy数组的concatenation函数\n",
    "   + Series\n",
    "   + DataFrame\n",
    " + 合并重叠数据  \n",
    " combine_first方法\n",
    "     + Series\n",
    "     + DataFrame\n",
    "\n",
    "\n",
    "+ 重塑和轴向选择\n",
    " + 重塑层次化索引\n",
    "   + stack：将数据的列“选择”为行\n",
    "   + unstack：将数据的行“选择”为列\n",
    " + 将“长格式”旋转为“宽格式”\n",
    " 等价于set_index创建层次化索引，再用unstack重塑\n",
    "\n",
    "\n",
    "+ 数据转换\n",
    " + 移除重复数据\n",
    " + 利用函数或映射进行数据转换  \n",
    "map方法，实现元素级转换以及其他数据清理工作的便捷方式\n",
    " + 替换值\n",
    " + 重命名轴索引\n",
    "   + map方法\n",
    "   + rename方法\n",
    " + 离散化和面元分化\n",
    "   + cut函数\n",
    "   + qcut函数\n",
    " + 检测和过滤异常值\n",
    " + 排列和随机采样\n",
    "   + 随机重排序\n",
    "   + 选取随机子集（不重复抽样）\n",
    "   + 选取样本（重复抽样）\n",
    " + 计算指标/哑变量\n",
    "   + 每行只属于一个分类\n",
    "   + 每行同属于多个分类\n",
    "   + 离散化与哑变量的结合\n",
    "\n",
    "\n",
    "+ 字符串操作\n",
    " + 字符串对象方法\n",
    " + 正则表达式\n",
    "   + re模块中的re对象\n",
    "   + re.compile编译regex对象\n",
    "      + 模式匹配\n",
    "      + 替换\n",
    "      + 拆分\n",
    " + pandas中矢量化的字符串函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据库风格的DataFrame合并\n",
    "列对列连接，DataFrame对象中的索引被丢弃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge函数的参数\n",
    "+ left  \n",
    "参与合并的左侧DataFrame\n",
    "+ right  \n",
    "参与合并的右侧DataFrame\n",
    "+ how  \n",
    "“inner”、“outer”、“left”、“right”其中之一。默认为“inner”\n",
    "+ on  \n",
    "用于连接的列名。必须存在于左右两个DataFrame对象中。如果未指定，且其他连接键也未指定，则以left和right列名的交集作为连接键\n",
    "+ left_on  \n",
    "左侧DataFrame中用作连接键的列\n",
    "+ right_on  \n",
    "右侧DataFrame中用作连接键的列\n",
    "+ left_index  \n",
    "将左侧的行索引用作连接键\n",
    "+ right_index  \n",
    "类似于left_index\n",
    "+ sort  \n",
    "根据连接键对合并后的数据进行排序，默认为True。有时在处理大数据集时，禁用该选项可获得更好的性能\n",
    "+ suffixes  \n",
    "字符串值元组，用于追加到重叠列名的末尾，默认为（‘_x’，‘_y’）。例如，如果左右两个DataFrame对象都有“data”，则结果中就会出现“data_x”和“data_y”\n",
    "+ copy  \n",
    "设置为False，可以在某些特殊情况下避免将数据复制到结果数据结构中。默认总是复制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一个键"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 多对一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
    "                 'data1': range(7)})\n",
    "df2 = DataFrame({'key': ['a', 'b', 'd'],\n",
    "                 'data2': range(3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2) # 如果没有指定，merge就会将重叠列的列名当做键"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='key') # 显式指定按哪个列连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = DataFrame({'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
    "                 'data1': range(7)})\n",
    "df4 = DataFrame({'rkey': ['a', 'b', 'd'],\n",
    "                 'data2': range(3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, left_on='lkey', right_on='rkey') # 两个对象的列名不同，可以分别指定左键、右键"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how='outer') # 默认内连接“inner”，结果中的键是交集；其他方式还有“left”、“right”、“outer”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 多对多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'],\n",
    "                 'data1': range(6)})\n",
    "df2 = DataFrame({'key': ['a', 'b', 'a', 'b', 'd'],\n",
    "                 'data2': range(5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='key', how='left') # 多对多连接产生的是行的笛卡尔积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多个键"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left = DataFrame({'key1': ['foo', 'foo', 'bar'],\n",
    "                  'key2': ['one', 'two', 'one'],\n",
    "                  'lval': [1, 2, 3]})\n",
    "right = DataFrame({'key1': ['foo', 'foo', 'bar', 'bar'],\n",
    "                   'key2': ['one', 'one', 'one', 'two'],\n",
    "                   'rval': [4, 5, 6, 7]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, on=['key1', 'key2'], how='outer') # 多个键进行合并，传入一个由列名组成的列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对重复列名的处理\n",
    "suffixes选项，用于指定附加到左右两个DataFrame对象的重叠列名上的字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, on='key1', suffixes=('_left', '_right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 索引上的合并"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 列对索引\n",
    "传入left_index=True或right_index=True（或两个都传）以说明索引应该被用作连接键"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left1 = DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],\n",
    "                  'value': range(6)})\n",
    "right1 = DataFrame({'group_val': [3.5, 7]}, index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(left1, right1, left_on='key', right_index=True) # 左侧DataFrame的列对右侧DataFrame的键"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(left1, right1, left_on='key', right_index=True, how='outer') # 默认内连接“inner”，通过how参数指定外连接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 层次化索引\n",
    "以列表的形式指明用作合并键的多个列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lefth = DataFrame({'key1': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "                   'key2': [2000, 2001, 2002, 2001, 2002],\n",
    "                   'data': np.arange(5.)})\n",
    "righth = DataFrame(np.arange(12).reshape((6, 2)),\n",
    "                   index=[['Nevada', 'Nevada', 'Ohio', 'Ohio', 'Ohio', 'Ohio'],\n",
    "                          [2001, 2000, 2000, 2000, 2001, 2002]],\n",
    "                   columns=['event1', 'event2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(lefth, righth, left_on=['key1', 'key2'], right_index=True) # left_on列表中的键，对应右侧DataFrame的MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(lefth, righth, left_on=['key1', 'key2'],\n",
    "         right_index=True, how='outer') # 默认内连接“inner”，通过how参数指定外连接 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 索引对索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left2 = DataFrame([[1., 2.], [3., 4.], [5., 6.]], index=['a', 'c', 'e'],\n",
    "                 columns=['Ohio', 'Nevada'])\n",
    "right2 = DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],\n",
    "                   index=['b', 'c', 'd', 'e'], columns=['Missouri', 'Alabama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(left2, right2, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### join方法\n",
    "默认按索引连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left2.join(right2, how='outer') # 默认左连接“left”，通过how参数指定外连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left1.join(right1, on='key') # on参数，支持参数DataFrame的索引跟调用者DataFrame的某个列之间的连接，left1的‘key’列与right1的索引匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 一组DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "another = DataFrame([[7., 8.], [9., 10.], [11., 12.], [16., 17.]],\n",
    "                    index=['a', 'c', 'e', 'f'], columns=['New York', 'Oregon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left2.join([right2, another]) # 默认左连接“left”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 轴向连接\n",
    "concat函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy数组的concatenation函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.arange(12).reshape((3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.concatenate([arr, arr], axis=1) # 默认沿0轴连接，设置axis参数沿1轴连接（即横向连接）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concat函数的参数\n",
    "+ objs  \n",
    "参与连接的pandas对象的列表或字典。唯一必需的参数\n",
    "+ axis  \n",
    "指明连接的轴向。默认为0\n",
    "+ join  \n",
    "“inner”、“outer”其中之一，默认为“outer”。指明其他轴向上的索引是按交集（inner）还是并集（outer）进行合并\n",
    "+ join_axes  \n",
    "指明用于其他n-1条轴的索引，不执行并集/交集运算\n",
    "+ keys  \n",
    "与连接对象有关的值，用于形成连接轴向上的层次化索引。可以是任意值的列表或数组、元祖数组、数组列表（如果将levels设置成多级数组的话）\n",
    "+ levels  \n",
    "指定用作层次化索引各级别上的索引，如果设置了keys的话\n",
    "+ names  \n",
    "用于创建分层级别的名称，如果设置了keys和（或）levels的话\n",
    "+ verify_integrity  \n",
    "检查结果对象新轴上的重复情况，如果发现则引发异常。默认（False）允许重复\n",
    "+ ignore_index  \n",
    "不保留连接轴上的索引，产生一组新索引range(total_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1 = Series([0, 1], index=['a', 'b'])\n",
    "s2 = Series([2, 3, 4], index=['c', 'd', 'e'])\n",
    "s3 = Series([5, 6], index=['f', 'g'])\n",
    "s4 = pd.concat([s1 * 5, s3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s2, s3]) # 默认沿0轴连接（即纵向拼接）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s2, s3], axis=1) # 传入axis=1（即横向连接），结果变成DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s4], axis=1, join='inner') # 默认外连接，传入join=‘inner’，设置内连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s4], axis=1, join_axes=[['a', 'c', 'b', 'e']]) # join_axes指定其他轴上使用的索引，此处沿1轴连接，指定结果DataFrame的行索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s1, s3], keys=['one', 'two', 'three']) # 沿0轴连接时，通过keys参数，在连接轴上创建一个层次化索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s2, s3], axis=1, keys=['one', 'two', 'three']) # 沿1轴连接时，由于Series没有1轴，设置keys参数，keys会成为DataFrame的列头"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = DataFrame(np.arange(6).reshape(3, 2), index=['a', 'b', 'c'],\n",
    "                columns=['one', 'two'])\n",
    "df2 = DataFrame(5 + np.arange(4).reshape(2, 2), index=['a', 'c'],\n",
    "                columns=['three', 'four'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1, keys=['level1', 'level2']) # keys参数在连接轴上创建层次化索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat({'level1': df1, 'level2': df2}, axis=1) # 传入的不是列表而是字典，则字典的键会被当做keys参数的值，以上两种方式等价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1, keys=['level1', 'level2'],\n",
    "          names=['upper', 'lower']) # 给keys创建的层次化索引，赋予names属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = DataFrame(np.random.randn(3, 4), columns=['a', 'b', 'c', 'd'])\n",
    "df2 = DataFrame(np.random.randn(2, 3), columns=['b', 'd', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], ignore_index=True) # 丢弃连接轴上原有的索引，产生新的数字索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并重叠数据\n",
    "combine_first方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Series([np.nan, 2.5, np.nan, 3.5, 4.5, np.nan],\n",
    "           index=['f', 'e', 'd', 'c', 'b', 'a'])\n",
    "b = Series(np.arange(len(a), dtype=np.float64),\n",
    "           index=['f', 'e', 'd', 'c', 'b', 'a'])\n",
    "b[-1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(pd.isnull(a), b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[:-2].combine_first(a[2:]) # 合并后的结果是b[:-2]与a[2:]的并集，重复值取调用者对象中的值，只有调用者中缺失值才取参数者，以上两种方式等价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = DataFrame({'a': [1., np.nan, 5., np.nan],\n",
    "                 'b': [np.nan, 2., np.nan, 6.],\n",
    "                 'c': range(2, 18, 4)})\n",
    "df2 = DataFrame({'a': [5., 4., np.nan, 3., 7.],\n",
    "                 'b': [np.nan, 3., 4., 6., 8.]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.combine_first(df2) # 合并后的结果是df1和df2的并集，重复值取调用者对象中的值，只有调用者中缺失值才取参数者"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重塑和轴向选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重塑层次化索引\n",
    "+ stack  \n",
    "将数据的列“旋转”为行\n",
    "+ unstack  \n",
    "将数据的行“旋转”为列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = DataFrame(np.arange(6).reshape((2, 3)),\n",
    "                 index=pd.Index(['Ohio', 'Colorado'], name='state'),\n",
    "                 columns=pd.Index(['one', 'two', 'three'], name='number'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = data.stack() # 将列转换为行，DataFrame转换为层次化索引的Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.unstack() # 将行转换为列，层次化索引的Series转换为DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.unstack(0) # 默认情况下，stack和unstack操作的是最内层，传入分层级别的编号或名称，对其他级别进行操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.unstack('state') # 传入分层级别的名称，以上两种方式等价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1 = Series([0, 1, 2, 3], index=['a', 'b', 'c', 'd'])\n",
    "s2 = Series([4, 5, 6], index=['c', 'd', 'e'])\n",
    "data2 = pd.concat([s1, s2], keys=['one', 'two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2.unstack() # 如果不是所有的级别值都能在分组中找到，unstack操作会引入缺失值NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2.unstack().stack() # stack默认会滤除缺失数据，因此unstack和stack运算可逆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2.unstack().stack(dropna=False) # 通过dropna=False，则保留缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame({'left': result, 'right': result + 5},\n",
    "               columns=pd.Index(['left', 'right'], name='side'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.unstack('state')\n",
    "df.unstack('state').stack('side') # 对DataFrame进行stack和unstack操作时，作为旋转轴的级别会成为结果中的最低级别，被放置在最内层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将“长格式”旋转为“宽格式”\n",
    "pivot方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ch07/macrodata.csv')\n",
    "periods = pd.PeriodIndex(year=data.year, quarter=data.quarter, name='date')\n",
    "data = DataFrame(data.to_records(),\n",
    "                 columns=pd.Index(['realgdp', 'infl', 'unemp'], name='item'),\n",
    "                 index=periods.to_timestamp('D', 'end'))\n",
    "\n",
    "ldata = data.stack().reset_index().rename(columns={0: 'value'}) # 引入“长格式”的时间序列数据\n",
    "wdata = ldata.pivot('date', 'item', 'value') # 将“长格式”旋转为“宽格式”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivoted = ldata.pivot('date', 'item', 'value') # 前两个参数值分别是用作行和列索引的列名，最后一个参数值则是用于填充DataFrame的数据列的列名\n",
    "pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldata['value2'] = np.random.randn(len(ldata))\n",
    "ldata[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivoted = ldata.pivot('date', 'item') # 有两个需要参与重塑的数据列（value和 value2），如果忽略最后一个参数，得到的DataFrame会带有层次化的列，value在外层，item在内层\n",
    "pivoted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unstacked = ldata.set_index(['date', 'item']).unstack('item') # pivot实际上是个快捷方式：用set_index创建层次化索引，再用unstack重塑\n",
    "unstacked[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 移除重复数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = DataFrame({'k1': ['one'] * 3 + ['two'] * 4,\n",
    "                  'k2': [1, 1, 2, 3, 3, 4, 4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.duplicated() # duplicated方法返回一个布尔型Series，表示各行是否是重复行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates() # drop_duplicates方法，用于返回一个移除了重复行的DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['v1'] = range(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.duplicated(['k1'])\n",
    "data.drop_duplicates(['k1']) # 两种方法默认判断全部列，可以指定部分列进行重复项判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.duplicated(['k1', 'k2'], keep='last')\n",
    "data.drop_duplicates(['k1', 'k2'], keep='last') # 两种方法默认保留的是第一个出现的值组合，传入keep='last'则保留最后一个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用函数或映射进行数据转换\n",
    "map方法，实现元素级转换以及其他数据清理工作的便捷方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = DataFrame({'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami',\n",
    "                           'corned beef', 'Bacon', 'pastrami', 'honey ham',\n",
    "                           'nova lox'],\n",
    "                  'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meat_to_animal = {\n",
    "  'bacon': 'pig',\n",
    "  'pulled pork': 'pig',\n",
    "  'pastrami': 'cow',\n",
    "  'corned beef': 'cow',\n",
    "  'honey ham': 'pig',\n",
    "  'nova lox': 'salmon'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['animal'] = data['food'].map(str.lower).map(meat_to_animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['food'].map(lambda x: meat_to_animal[x.lower()]) # map方法可以接受一个函数或含有映射关系的字典型对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 替换值\n",
    "replace方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Series([1., -999., 2., -999., -1000., 3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.replace(-999, np.nan) # 将-999替换为NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.replace([-999, -1000], np.nan) # 一次性替换多个值，传入一个由待替换值组成的列表以及一个替换值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.replace([-999, -1000], [np.nan, 0]) # 对不同的值进行不同的替换，传入一个由替换关系组成的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.replace({-999: np.nan, -1000: 0}) # 对不同的值进行不同的替换，也可以传入一个代表映射关系的字典，以上两种方式等价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重命名轴索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = DataFrame(np.arange(12).reshape((3, 4)),\n",
    "                 index=['Ohio', 'Colorado', 'New York'],\n",
    "                 columns=['one', 'two', 'three', 'four'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.index.map(str.upper) # 同Series一样，轴标签也有map方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.index = data.index.map(str.upper) # 将其赋值给index，可以对DataFrame进行就地修改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.rename(index=str.title, columns=str.upper) # 创建修改后的副本（而非就地修改），可以对index和columns传入函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.rename(index={'OHIO': 'INDIANA'},\n",
    "            columns={'three': 'peekaboo'}) # 也可以对index和columns传入字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = data.rename(index={'OHIO': 'INDIANA'}, inplace=True) # 通过inplace参数设置就地修改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 离散化和面元划分\n",
    "将连续数据离散化或拆分为“面元”（bin）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cut函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = [18, 25, 35, 60, 100]\n",
    "cats = pd.cut(ages, bins) # cut函数，第一个参数是待离散化的连续数据，第二个参数是划分的区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats.labels\n",
    "cats.levels # cut函数返回的Categorical对象，有labels和levels两个属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.value_counts(cats) # 返回每个区间的元素数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.cut(ages, [18, 26, 36, 61, 100], right=False) # 默认左开右闭区间，设置right=False左闭右开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_names = ['Youth', 'YoungAdult', 'MiddleAged', 'Senior']\n",
    "pd.cut(ages, bins, labels=group_names) # 设置面元的名称，将labels选项设置为一个列表或数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.random.rand(20) # 如果向cut函数传入的是面元的数量而不是区间，会根据数据的最小值、最大值计算等长面元\n",
    "pd.cut(data, 4, precision=2) # precision参数，设置封箱时区间边界小数点后保留的位数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qcut函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.random.randn(1000)\n",
    "cats = pd.qcut(data, 4) # 根据样本分位数对数据进行面元划分（每个面元内元素数量基本相等）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.value_counts(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.]) # 第二个参数，自定义分位数，列表必须以0开头，以1结尾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检测和过滤异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "data = DataFrame(np.random.randn(1000, 4))\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = data[3]\n",
    "col[np.abs(col) > 3] # 找出某列中绝对值大小超过3的值（布尔型索引）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[(np.abs(data) > 3).any(1)] # 找出含有绝对值大小超过3的值的行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[np.abs(data) > 3] = np.sign(data) * 3 # 将DataFrame中的值限制在-3到3以内（超过3的值设置为3）\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 排列和随机采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机重排序\n",
    "numpy.random.permutation函数，可以产生一个表示新顺序的整数数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame(np.arange(5 * 4).reshape((5, 4)))\n",
    "sampler = np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix[sampler]\n",
    "df.take(sampler) # 基于ix的索引操作或take函数，进行随机重排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 选取随机子集（不重复抽样）\n",
    "从permutation返回的数组中切下前k个元素，其中k为期望的子集大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.take(np.random.permutation(len(df))[:3]) # len函数返回df的行数，不重复抽样3行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 选取样本（重复抽样）\n",
    "numpy.random.randint函数，产生一组随机整数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag = np.array([5, 7, -1, 6, 4])\n",
    "sampler = np.random.randint(0, len(bag), size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draws = bag.take(sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算指标/哑变量\n",
    "get_dummies函数，DataFrame的某一列中含有k个不同的值，可以派生出一个k列矩阵或DataFrame（取值全为1和0）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 每行只属于一个分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'],\n",
    "                'data1': range(6)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(df['key']) # 参数是要计算哑变量的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df['key'], prefix='key') # 为生成的哑变量矩阵的列名添加前缀\n",
    "df_with_dummy = df[['data1']].join(dummies) # 将生成的哑变量矩阵添加至原DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 每行同属于多个分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnames = ['movie_id', 'title', 'genres']\n",
    "movies = pd.read_table('ch02/movielens/movies.dat', sep='::', header=None,\n",
    "                        names=mnames) # 读入ch02的MovieLens 1M数据集\n",
    "movies[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genre_iter = (set(x.split('|')) for x in movies.genres)\n",
    "genres = sorted(set.union(*genre_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummies = DataFrame(np.zeros((len(movies), len(genres))), columns=genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, gen in enumerate(movies.genres):\n",
    "    dummies.ix[i, gen.split('|')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_windic = movies.join(dummies.add_prefix('Genre_')) # df.add_prefix()，给df的所有列名添加前缀；同理还有df.add_suffix()\n",
    "movies_windic.ix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### 离散化与哑变量的结合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "pd.get_dummies(pd.cut(values, bins)) # 将连续数据离散化，进而转化为哑变量矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字符串操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字符串对象方法\n",
    "+ count  \n",
    "返回字串在字符串中的出现次数（非重叠）\n",
    "+ endswith、startswitch  \n",
    "如果字符串以某个后缀结尾（以某个前缀开头），则返回True\n",
    "+ join  \n",
    "将字符串用作连接其它字符串序列的分隔符\n",
    "+ index  \n",
    "如果在字符串中找到子串，则返回字串第一个字符所在的位置。如果没有找到，则引发ValueError\n",
    "+ find  \n",
    "如果在字符串中找到子串，则返回第一个发现的字串的第一个字符所在的位置。如果没有找到，则返回-1\n",
    "+ rfind  \n",
    "如果在字符串中找到子串，则返回最后一个发现的子串的第一个字符所在的位置。如果没有找到，则返回-1\n",
    "+ replace  \n",
    "用另一个字符串替换指定子串\n",
    "+ strip、rstrip、lstrip  \n",
    "去除空白符（包括换行符）\n",
    "+ split  \n",
    "通过指定的分隔符将字符串拆分为一组子串\n",
    "+ lower、upper  \n",
    "分别将字母字符转换为小写或大写\n",
    "+ ljust、rjust  \n",
    "用空格（或其他字符）填充字符串的空白侧以返回符合最低宽度的字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = 'a,b,  guido'\n",
    "val.split(',') # 以逗号分隔的字符串，用split拆分成数段，用列表组装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pieces = [x.strip() for x in val.split(',')] # split与strip结合，修剪空白符（包括换行符）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first, second, third = pieces\n",
    "first + '::' + second + '::' + third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'::'.join(pieces) # 将列表中的子字符串以双冒号分隔符的形式连接起来，返回新的字符串，以上两种方式等价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'guido' in val # 子串定位，返回True或False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val.index(',') # 子串定位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val.find(':') # 子串定位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val.index(':') # 如果找不到字符串，index引发异常，find返回-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val.count(',') # 返回指定子串的出现次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val.replace(',', '::') # 用第二个参数替换为第一个参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val.replace(',', '') # 第二个参数如果传入空字符串可用于删除模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则表达式\n",
    "正则表达式（regex）提供了一种灵活的在文本中搜索或匹配字符串模式的方式。\n",
    "Python内置的re模块负责对字符串应用正则表达式。re模块的函数可以分为三大类：模式匹配、替换以及拆分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ findall、finditer  \n",
    "返回字符串中所有的非重叠匹配模式。findall返回的是由所有模式组成的列表，而finditer则通过一个迭代器逐个返回\n",
    "+ match  \n",
    "从字符串起始位置匹配模式，还可以对模式各部分进行分组。如果匹配到模式，则返回一个匹配项对象，否则返回None\n",
    "+ search  \n",
    "扫描整个字符串以匹配模式。如果找到则返回一个匹配项对象。跟match不同，其匹配项可以位于字符串的任意位置，而不仅仅是起始处\n",
    "+ split  \n",
    "根据找到的模式将字符串拆分为数段\n",
    "+ sub、subn  \n",
    "将字符串中所有的（sub）或前n个（subn）模式替换为指定表达式。在替换字符串中可以通过\\1、\\2等符号表示各分组项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### re模块中的re对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"foo    bar\\t baz  \\tqux\"\n",
    "re.split('\\s+', text) # 描述一个或多个空白符的regex是\\s+，调用re时，正则表达式会先被编译，然后再在text上调用其split方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### re.compile编译regex对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex = re.compile('\\s+') # 用re.compile自己编译regex以得到一个可重用regex对象\n",
    "regex.split(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 模式匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex.findall(text) # 得到符合regex的所有匹配项，使用findall方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Dave dave@google.com\n",
    "Steve steve@gmail.com\n",
    "Rob rob@gmail.com\n",
    "Ryan ryan@yahoo.com\n",
    "\"\"\"\n",
    "pattern = r'[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}' # 能够识别电子邮件地址的正则表达式\n",
    "\n",
    "regex = re.compile(pattern, flags=re.IGNORECASE) # # re.IGNORECASE的作用是使正则表达式对大小写不敏感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex.findall(text) # findall，返回字符串中所有的匹配项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = regex.search(text) # search，返回第一个匹配项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text[m.start():m.end()] # 以特殊的匹配项对象形式返回，告诉我们模式在原字符串中的起始和结束位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(regex.match(text)) # match，匹配出现在字符串开头的模式，未匹配到则返回None，匹配到则返回特殊的匹配项对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(regex.sub('REDACTED', text)) # sub，将匹配到的所有模式替换为指定字符串，并返回所得到的新字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})' # 将电邮地址分为3部分：用户名、域名、域后缀，将待分段的模式各部分用圆括号包起来\n",
    "regex = re.compile(pattern, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = regex.match('wesm@bright.net')\n",
    "m.groups() # 由上述正则表达式所产生的匹配项对象，可以通过其groups方法返回一个由模式各段组成的元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex.findall(text) # 对于带有分组功能的模式，findall会返回一个元组列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(regex.sub(r'Username: \\1, Domain: \\2, Suffix: \\3', text)) # sub通过诸如\\1，\\2之类的特殊符号访问各匹配项中的分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex = re.compile(r\"\"\"\n",
    "    (?P<username>[A-Z0-9._%+-]+)\n",
    "    @\n",
    "    (?P<domain>[A-Z0-9.-]+)\n",
    "    \\.\n",
    "    (?P<suffix>[A-Z]{2,4})\"\"\", flags=re.IGNORECASE|re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = regex.match('wesm@bright.net')\n",
    "m.groupdict() # 通过groupdict方法返回一个带有分组名称的字典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas中矢量化的字符串函数\n",
    "+ cat  \n",
    "实现元素级的字符串连接操作，可指定分隔符\n",
    "+ contains  \n",
    "返回表示各字符串是否含有指定模式的布尔型数组\n",
    "+ count  \n",
    "模式的出现次数\n",
    "+ endswith、startswitch  \n",
    "相当于对各个元素执行x.endswith(pattern)或x.startswith(patter)\n",
    "+ findall  \n",
    "计算各字符串的模式列表\n",
    "+ get  \n",
    "获取各元素的第i个字符\n",
    "+ join  \n",
    "根据指定的分隔符将Series中各元素的字符串连接起来\n",
    "+ len  \n",
    "计算各字符串的长度\n",
    "+ lower、upper  \n",
    "转换大小写。相当于对各个元素执行x.lower()或x.upper()\n",
    "+ match  \n",
    "根据指定的正则表达式对各个元素执行re.match\n",
    "+ pad  \n",
    "在字符串的左边、右边或左右两边添加空白符\n",
    "+ center  \n",
    "相当于pad(side='both')\n",
    "+ repeat  \n",
    "重复值。例如，s.str.repeat(3)相当于对各个字符串执行x*3\n",
    "+ replace  \n",
    "用指定字符串替换找到的字符\n",
    "+ slice  \n",
    "对Series中的各个字符串进行子串截取\n",
    "+ split  \n",
    "根据分隔符或正则表达式对字符串进行拆分\n",
    "+ strip、rstrip、lstrip  \n",
    "去除空白符，包括换行符。相当于对各个元素执行x.strip()、x.rstrip()、x.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {'Dave': 'dave@google.com', 'Steve': 'steve@gmail.com',\n",
    "        'Rob': 'rob@gmail.com', 'Wes': np.nan}\n",
    "data = Series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.isnull() # 定位缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通过Series的str属性，可以访问能够跳过NA值的字符串操作方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.str.contains('gmail') # 检查各个电邮地址是否含有“gmail”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.str.findall(pattern, flags=re.IGNORECASE) # findall，寻找匹配pattern的所有模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矢量化的元素获取操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = data.str.match(pattern, flags=re.IGNORECASE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### str.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches.str.get(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 在str属性上使用索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches.str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对字符串进行子串截取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.str[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: USDA Food Database"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{\n",
    "  \"id\": 21441,\n",
    "  \"description\": \"KENTUCKY FRIED CHICKEN, Fried Chicken, EXTRA CRISPY,\n",
    "Wing, meat and skin with breading\",\n",
    "  \"tags\": [\"KFC\"],\n",
    "  \"manufacturer\": \"Kentucky Fried Chicken\",\n",
    "  \"group\": \"Fast Foods\",\n",
    "  \"portions\": [\n",
    "    {\n",
    "      \"amount\": 1,\n",
    "      \"unit\": \"wing, with skin\",\n",
    "      \"grams\": 68.0\n",
    "    },\n",
    "\n",
    "    ...\n",
    "  ],\n",
    "  \"nutrients\": [\n",
    "    {\n",
    "      \"value\": 20.8,\n",
    "      \"units\": \"g\",\n",
    "      \"description\": \"Protein\",\n",
    "      \"group\": \"Composition\"\n",
    "    },\n",
    "\n",
    "    ...\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "db = json.load(open('ch07/foods-2011-10-03.json'))\n",
    "len(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db[0]['nutrients'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nutrients = DataFrame(db[0]['nutrients'])\n",
    "nutrients[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info_keys = ['description', 'group', 'id', 'manufacturer']\n",
    "info = DataFrame(db, columns=info_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.value_counts(info.group)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nutrients = []\n",
    "\n",
    "for rec in db:\n",
    "    fnuts = DataFrame(rec['nutrients'])\n",
    "    fnuts['id'] = rec['id']\n",
    "    nutrients.append(fnuts)\n",
    "\n",
    "nutrients = pd.concat(nutrients, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nutrients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nutrients.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nutrients = nutrients.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_mapping = {'description' : 'food',\n",
    "               'group'       : 'fgroup'}\n",
    "info = info.rename(columns=col_mapping, copy=False)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_mapping = {'description' : 'nutrient',\n",
    "               'group' : 'nutgroup'}\n",
    "nutrients = nutrients.rename(columns=col_mapping, copy=False)\n",
    "nutrients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndata = pd.merge(nutrients, info, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndata.ix[30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = ndata.groupby(['nutrient', 'fgroup'])['value'].quantile(0.5)\n",
    "result['Zinc, Zn'].order().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "by_nutrient = ndata.groupby(['nutgroup', 'nutrient'])\n",
    "\n",
    "get_maximum = lambda x: x.xs(x.value.idxmax())\n",
    "get_minimum = lambda x: x.xs(x.value.idxmin())\n",
    "\n",
    "max_foods = by_nutrient.apply(get_maximum)[['value', 'food']]\n",
    "\n",
    "# make the food a little smaller\n",
    "max_foods.food = max_foods.food.str[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_foods.ix['Amino Acids']['food']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
